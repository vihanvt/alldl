{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGCmIngf2iS8",
        "outputId": "1fa385bd-a412-4a58-f9db-c4d0f831cb1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
            "0        -114.31     34.19                15.0       5612.0          1283.0   \n",
            "1        -114.47     34.40                19.0       7650.0          1901.0   \n",
            "2        -114.56     33.69                17.0        720.0           174.0   \n",
            "3        -114.57     33.64                14.0       1501.0           337.0   \n",
            "4        -114.57     33.57                20.0       1454.0           326.0   \n",
            "...          ...       ...                 ...          ...             ...   \n",
            "16995    -124.26     40.58                52.0       2217.0           394.0   \n",
            "16996    -124.27     40.69                36.0       2349.0           528.0   \n",
            "16997    -124.30     41.84                17.0       2677.0           531.0   \n",
            "16998    -124.30     41.80                19.0       2672.0           552.0   \n",
            "16999    -124.35     40.54                52.0       1820.0           300.0   \n",
            "\n",
            "       population  households  median_income  median_house_value  \n",
            "0          1015.0       472.0         1.4936             66900.0  \n",
            "1          1129.0       463.0         1.8200             80100.0  \n",
            "2           333.0       117.0         1.6509             85700.0  \n",
            "3           515.0       226.0         3.1917             73400.0  \n",
            "4           624.0       262.0         1.9250             65500.0  \n",
            "...           ...         ...            ...                 ...  \n",
            "16995       907.0       369.0         2.3571            111400.0  \n",
            "16996      1194.0       465.0         2.5179             79000.0  \n",
            "16997      1244.0       456.0         3.0313            103600.0  \n",
            "16998      1298.0       478.0         1.9797             85800.0  \n",
            "16999       806.0       270.0         3.0147             94600.0  \n",
            "\n",
            "[17000 rows x 9 columns]\n",
            "6\n",
            "torch.Size([17000, 6])\n",
            "tensor([[0.1070],\n",
            "        [0.1342],\n",
            "        [0.1458],\n",
            "        ...,\n",
            "        [0.1827],\n",
            "        [0.1460],\n",
            "        [0.1641]])\n",
            "torch.Size([17000, 1])\n"
          ]
        }
      ],
      "source": [
        "#house price detection basic model\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "df_train=pd.read_csv(\"/content/sample_data/california_housing_train.csv\")\n",
        "print(df_train)\n",
        "features=[\"housing_median_age\",\"total_rooms\",\"total_bedrooms\",\"population\",\"households\",\"median_income\"]\n",
        "inp_dim=len(features)\n",
        "print(inp_dim)\n",
        "\n",
        "out_dim=1\n",
        "num_layers=4\n",
        "batch_size=16\n",
        "\n",
        "x_train=df_train[features].values\n",
        "#scaling the values\n",
        "scaler=MinMaxScaler()\n",
        "x_train=scaler.fit_transform(x_train)\n",
        "x_train=torch.from_numpy(x_train).float()\n",
        "y_train=df_train[\"median_house_value\"].values\n",
        "y_train=y_train.reshape(-1,1)\n",
        "y_train=scaler.fit_transform(y_train)\n",
        "y_train=torch.from_numpy(y_train).float()\n",
        "print(x_train.shape)\n",
        "print(y_train)\n",
        "print(y_train.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test data\n",
        "df_test=pd.read_csv(\"/content/sample_data/california_housing_test.csv\")\n",
        "print(df_test.head)\n",
        "x_test=df_test[features].values\n",
        "x_test=scaler.fit_transform(x_test)\n",
        "x_test=torch.from_numpy(x_test).float()\n",
        "y_test=df_test[\"median_house_value\"].values\n",
        "y_test=y_test.reshape(-1,1)\n",
        "y_test=scaler.fit_transform(y_test)\n",
        "y_test=torch.from_numpy(y_test).float()\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "train_unsplit_data=torch.utils.data.TensorDataset(x_train,y_train)\n",
        "ratio=0.8\n",
        "split_index=int(len(x_train)*ratio)\n",
        "x_train,x_val=x_train[:split_index],x_train[split_index:]\n",
        "y_train,y_val=y_train[:split_index],y_train[split_index:]\n",
        "train_dataset=torch.utils.data.TensorDataset(x_train,y_train)\n",
        "val_dataset=torch.utils.data.TensorDataset(x_val,y_val)\n",
        "val_loader=torch.utils.data.DataLoader(val_dataset,batch_size,shuffle=True)\n",
        "train_loader=torch.utils.data.DataLoader(train_dataset,batch_size,shuffle=True)\n",
        "test_dataset=torch.utils.data.TensorDataset(x_test,y_test)\n",
        "test_loader=torch.utils.data.DataLoader(test_dataset,batch_size,shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWMUTYIa6WQH",
        "outputId": "6f31192a-5dcf-4d51-c571-ece84c15b556"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method NDFrame.head of       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
            "0       -122.05     37.37                27.0       3885.0           661.0   \n",
            "1       -118.30     34.26                43.0       1510.0           310.0   \n",
            "2       -117.81     33.78                27.0       3589.0           507.0   \n",
            "3       -118.36     33.82                28.0         67.0            15.0   \n",
            "4       -119.67     36.33                19.0       1241.0           244.0   \n",
            "...         ...       ...                 ...          ...             ...   \n",
            "2995    -119.86     34.42                23.0       1450.0           642.0   \n",
            "2996    -118.14     34.06                27.0       5257.0          1082.0   \n",
            "2997    -119.70     36.30                10.0        956.0           201.0   \n",
            "2998    -117.12     34.10                40.0         96.0            14.0   \n",
            "2999    -119.63     34.42                42.0       1765.0           263.0   \n",
            "\n",
            "      population  households  median_income  median_house_value  \n",
            "0         1537.0       606.0         6.6085            344700.0  \n",
            "1          809.0       277.0         3.5990            176500.0  \n",
            "2         1484.0       495.0         5.7934            270500.0  \n",
            "3           49.0        11.0         6.1359            330000.0  \n",
            "4          850.0       237.0         2.9375             81700.0  \n",
            "...          ...         ...            ...                 ...  \n",
            "2995      1258.0       607.0         1.1790            225000.0  \n",
            "2996      3496.0      1036.0         3.3906            237200.0  \n",
            "2997       693.0       220.0         2.2895             62000.0  \n",
            "2998        46.0        14.0         3.2708            162500.0  \n",
            "2999       753.0       260.0         8.5608            500001.0  \n",
            "\n",
            "[3000 rows x 9 columns]>\n",
            "torch.Size([3000, 6])\n",
            "torch.Size([3000, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#making the regression model now\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)\n",
        "class Housing(nn.Module):\n",
        "    def __init__(self,inp_dim,out_dim,num_layers,batch_size):\n",
        "        super(Housing,self).__init__()\n",
        "        self.inp_dim=inp_dim\n",
        "        self.out_dim=out_dim\n",
        "        self.num_layers=out_dim\n",
        "        self.batch_size=batch_size\n",
        "        self.layer1=nn.Linear(inp_dim,32)#32 neurons in the 1st hidden layer\n",
        "        self.layer2=nn.Linear(32,16)#16 neurons in the 2nd hidden layer\n",
        "        self.layer3=nn.Linear(16,1)\n",
        "    def forward(self,x):\n",
        "        x=F.relu(self.layer1(x))\n",
        "        x=F.relu(self.layer2(x))\n",
        "        output=self.layer3(x)\n",
        "        return output\n",
        "\n",
        "epochs=50\n",
        "lr=0.001\n",
        "lossfunc=nn.MSELoss()\n",
        "model=Housing(inp_dim,out_dim,num_layers,batch_size)\n",
        "optimizer=optim.Adam(model.parameters(),lr)\n",
        "print(\"Training started\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    train_loss=0.0\n",
        "    for inp,out in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        output=model(inp)\n",
        "        loss_val=lossfunc(output,out)\n",
        "        loss_val.backward()\n",
        "        optimizer.step()\n",
        "        train_loss+=loss_val.item()\n",
        "\n",
        "    model.eval()\n",
        "    val_loss=0.0\n",
        "    with torch.no_grad():\n",
        "        for inp,out in val_loader:\n",
        "            output=model(inp)\n",
        "            val_loss+=lossfunc(output,out).item()\n",
        "    print(f\"Epoch{epoch},Train Loss:{train_loss:.4f},Val Loss:{val_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzYaEzin53Oi",
        "outputId": "ff6e890a-35f0-4d16-bed5-0382554bdca1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "Training started\n",
            "Epoch0,Train Loss:35.8228,Val Loss:6.3657\n",
            "Epoch1,Train Loss:20.8462,Val Loss:6.0479\n",
            "Epoch2,Train Loss:20.0360,Val Loss:5.8534\n",
            "Epoch3,Train Loss:19.4632,Val Loss:6.1753\n",
            "Epoch4,Train Loss:19.0336,Val Loss:5.3435\n",
            "Epoch5,Train Loss:18.5201,Val Loss:5.5727\n",
            "Epoch6,Train Loss:18.3453,Val Loss:5.1809\n",
            "Epoch7,Train Loss:17.7836,Val Loss:5.5347\n",
            "Epoch8,Train Loss:17.5788,Val Loss:4.9413\n",
            "Epoch9,Train Loss:17.3208,Val Loss:5.0782\n",
            "Epoch10,Train Loss:17.1957,Val Loss:4.7423\n",
            "Epoch11,Train Loss:16.9564,Val Loss:4.7239\n",
            "Epoch12,Train Loss:16.7746,Val Loss:4.8020\n",
            "Epoch13,Train Loss:16.7599,Val Loss:4.9801\n",
            "Epoch14,Train Loss:16.5920,Val Loss:4.6712\n",
            "Epoch15,Train Loss:16.4255,Val Loss:4.8144\n",
            "Epoch16,Train Loss:16.2588,Val Loss:5.0935\n",
            "Epoch17,Train Loss:16.2872,Val Loss:4.6160\n",
            "Epoch18,Train Loss:16.1800,Val Loss:4.5575\n",
            "Epoch19,Train Loss:16.0817,Val Loss:4.5618\n",
            "Epoch20,Train Loss:16.0350,Val Loss:4.5699\n",
            "Epoch21,Train Loss:15.9454,Val Loss:4.5708\n",
            "Epoch22,Train Loss:15.9446,Val Loss:4.7635\n",
            "Epoch23,Train Loss:15.8850,Val Loss:5.1295\n",
            "Epoch24,Train Loss:15.7928,Val Loss:4.9324\n",
            "Epoch25,Train Loss:15.8121,Val Loss:4.7403\n",
            "Epoch26,Train Loss:15.6864,Val Loss:4.6730\n",
            "Epoch27,Train Loss:15.6862,Val Loss:4.9022\n",
            "Epoch28,Train Loss:15.5871,Val Loss:4.5918\n",
            "Epoch29,Train Loss:15.6334,Val Loss:5.3924\n",
            "Epoch30,Train Loss:15.5658,Val Loss:4.9127\n",
            "Epoch31,Train Loss:15.5668,Val Loss:4.7394\n",
            "Epoch32,Train Loss:15.5529,Val Loss:4.8132\n",
            "Epoch33,Train Loss:15.4166,Val Loss:4.9811\n",
            "Epoch34,Train Loss:15.3609,Val Loss:4.9023\n",
            "Epoch35,Train Loss:15.3375,Val Loss:4.7870\n",
            "Epoch36,Train Loss:15.4423,Val Loss:4.4809\n",
            "Epoch37,Train Loss:15.4821,Val Loss:5.0892\n",
            "Epoch38,Train Loss:15.3145,Val Loss:4.8269\n",
            "Epoch39,Train Loss:15.2380,Val Loss:4.8702\n",
            "Epoch40,Train Loss:15.2820,Val Loss:5.4709\n",
            "Epoch41,Train Loss:15.2366,Val Loss:4.5081\n",
            "Epoch42,Train Loss:15.2757,Val Loss:4.7246\n",
            "Epoch43,Train Loss:15.1824,Val Loss:4.6089\n",
            "Epoch44,Train Loss:15.2262,Val Loss:4.5822\n",
            "Epoch45,Train Loss:15.2049,Val Loss:4.5590\n",
            "Epoch46,Train Loss:15.2153,Val Loss:4.5373\n",
            "Epoch47,Train Loss:15.3218,Val Loss:4.5718\n",
            "Epoch48,Train Loss:15.2595,Val Loss:4.5284\n",
            "Epoch49,Train Loss:15.1041,Val Loss:4.5594\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_data = torch.tensor([[15, 200, 1283, 1015, 472, 1.493600]], dtype=torch.float32)\n",
        "\n",
        "input_scaled_np = scaler.transform(sample_data.numpy())\n",
        "input_scaled = torch.tensor(input_scaled_np, dtype=torch.float32).to(device)\n",
        "\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    pred_price = model(input_scaled).cpu().numpy()\n",
        "\n",
        "print(f\"Predicted median house value: ${pred_price[0][0]:,.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzXiIwlUG_u1",
        "outputId": "69f5c730-4ac3-4af2-93cb-9cbf0e51f8b2"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted median house value: $718.05\n"
          ]
        }
      ]
    }
  ]
}